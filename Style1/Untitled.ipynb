{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style 1\n",
    "\n",
    "In this mode, there will be a unified function definition. The array operations will operate ( preferably) on 1-D array, so it is useful for the functional chain approach, and can be integrated on oamap . \n",
    "\n",
    "The definitions will check if it is a Gpuarray or numpy/CPU array, and accordingly perform the operations. This will avoid GPUArray creation/copy everytime the function is called.\n",
    "\n",
    "An example implementation for calculation dot() operation on two arrays is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.gpuarray as gpuarray\n",
    "from pycuda.elementwise import ElementwiseKernel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(lst1, lst2):\n",
    "    if isinstance(lst1, gpuarray.GPUArray) and isinstance(lst1, gpuarray.GPUArray): #check for GPUArray\n",
    "        m = len(lst1)\n",
    "        #n= len(lst2)\n",
    "        #assert(m == n)\n",
    "        gpukern = ElementwiseKernel(\n",
    "        \"float *x, float *y,float *out, int m\",\n",
    "        \"out[i] = x[i]*y[i]\",\n",
    "        \"gpukern\",\n",
    "        )\n",
    "        out = gpuarray.empty_like(lst1)\n",
    "        gpukern(lst1, lst2, out, m)\n",
    "        return out\n",
    "    else:\n",
    "        return np.multiply(lst1, lst2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(4000000, dtype = np.float32)\n",
    "b = np.arange(4000000, dtype = np.float32)\n",
    "\n",
    "a_gpu = gpuarray.to_gpu(a.astype(np.float32))\n",
    "b_gpu = gpuarray.to_gpu(b.astype(np.float32))\n",
    "\n",
    "c = dot(a_gpu, b_gpu)  # can change arguments to a, b. The function should automatically dtermine the type, and operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "This approach will however, be of limited use for GPU acceleration, in case the actual size of 1-D arrays generated is very small (less than 50,000 ~ 60,000). The GPU Copy overhead itself will kill the runtime of the code. \n",
    "\n",
    "Furthermore, it can become complicated soon, if multidimensional arrays are involved. This can be reduced to some extent by using a more GPU focused library like pytorch, or vectorize the codes with numba"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
